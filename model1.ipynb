{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:- https://www.kaggle.com/datasets/mirichoi0218/insurance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# X = data.iloc[:,:-1]\n",
    "X = data.drop(['sex','children','region','charges'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         int64\n",
       "bmi       float64\n",
       "smoker     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi smoker\n",
       "0      19  27.900    yes\n",
       "1      18  33.770     no\n",
       "2      28  33.000     no\n",
       "3      33  22.705     no\n",
       "4      32  28.880     no\n",
       "...   ...     ...    ...\n",
       "1333   50  30.970     no\n",
       "1334   18  31.920     no\n",
       "1335   18  36.850     no\n",
       "1336   21  25.800     no\n",
       "1337   61  29.070    yes\n",
       "\n",
       "[1338 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.where((X.dtypes == object))\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot label encoding method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoderMethod(indices, data):\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(),indices )], remainder='passthrough')\n",
    "    return columnTransformer.fit_transform(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label ENCODING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabelEncoderMethod(series):\n",
    "    from sklearn import preprocessing\n",
    "    LE = preprocessing.LabelEncoder()\n",
    "    return LE.fit_transform(series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding x features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncodingSelection(X, threshold=10):\n",
    "    # Step 01 : Select the string col\n",
    "    string_cols = list(np.where((X.dtypes == object))[0])\n",
    "    one_hot_encoding_indices = []\n",
    "    \n",
    "    # Step 02: The number of categoty is 2 and more than threshold, label encode\n",
    "    for col in string_cols:\n",
    "        length = len(pd.unique(X[X.columns[col]]))\n",
    "        if length == 2 or length > threshold:\n",
    "            X[X.columns[col]] = LabelEncoderMethod(X[X.columns[col]])\n",
    "        else:\n",
    "            one_hot_encoding_indices.append(col)\n",
    "            \n",
    "    # Step 03: One hot encode otherwise \n",
    "    X = OneHotEncoderMethod(one_hot_encoding_indices, X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = EncodingSelection(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.9 ,  1.  ],\n",
       "       [33.77,  0.  ],\n",
       "       [33.  ,  0.  ],\n",
       "       ...,\n",
       "       [36.85,  0.  ],\n",
       "       [25.8 ,  0.  ],\n",
       "       [29.07,  1.  ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "sx = preprocessing.MinMaxScaler()\n",
    "sy = preprocessing.MinMaxScaler()\n",
    "\n",
    "scaled_x = sx.fit_transform(X)\n",
    "scaled_y = sy.fit_transform(Y.values.reshape(data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = np.append(scaled_x, X[:,:1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(scaled_x,scaled_y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adadelta, Adam, Adagrad, Adamax, Nadam, RMSprop \n",
    "from tensorflow.keras.losses import mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing behins here: ----------------\n",
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1119\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0688\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0459\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0388\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0336\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0267\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0244\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0225\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0130\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0129\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0126\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0124\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0123\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0120\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0120\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0117\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0117\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0115\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0114\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0113\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0111\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0111\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0110\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0100\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0099\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0098\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0097\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 996us/step - loss: 0.0097\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0097\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0096\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 996us/step - loss: 0.0095\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0095\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0095\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 966us/step - loss: 0.0095\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0095\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23e0d83b850>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SGD\n",
    "# Use the required optimizer to compile the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,activation = 'linear'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "print(\"Printing behins here: ----------------\")\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.0,\n",
    "    nesterov=False,),loss=tf.keras.losses.mse)\n",
    "train = model.fit(x_train,y_train,epochs=500)\n",
    "\n",
    "#loss over time\n",
    "plt.plot(train.history['loss'], label='loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend('SGD')\n",
    "# model.predict(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.35328615947889386"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,pred) # for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6038662866807989"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,pred) # for age bmi smoker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7568036916476395"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFOLD validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf  = KFold(n_splits=5, shuffle = True, random_state= 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # model.add(Ac)\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.0,\n",
    "        nesterov=False),loss=tf.keras.losses.mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'] ,label='loss')\n",
    "    plt.title('SGD')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend('12345')\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MINI_BATCH_SGD_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # model.add(Ac)\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.0,\n",
    "        nesterov=False),loss=tf.keras.losses.mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100, batch_size=20)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'] ,label='loss')\n",
    "    plt.title('SGD')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend('12345')\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOMENTUM_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # model.add(Ac)\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.2/(1+0.96*100),momentum=0.9,\n",
    "        nesterov=False),loss=tf.keras.losses.mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'] ,label='loss')\n",
    "    plt.title('SGD')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend('12345')\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NESTEROV_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # model.add(Ac)\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9,\n",
    "        nesterov=True),loss=tf.keras.losses.mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'] ,label='loss')\n",
    "    plt.title('SGD')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend('12345')\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RmsProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSPROP_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # model.add(Ac)\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-8) ,loss=tf.keras.losses.mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'] ,label='loss')\n",
    "    plt.title('SGD')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['1','2','3','4','5'])\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADAM_model(x_train, y_train, x_test, y_test):\n",
    "    #Creating Sequential Model\n",
    "    # lr_schedule = keras.optimizers.schedules.l\n",
    "    print(\"Printing behins here: ----------------\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1))\n",
    "    # Use the required optimizer to compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.2/(1+0.96*100),\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-8,\n",
    "        amsgrad=False,),loss=mse)\n",
    "    train = model.fit(x_train,y_train,epochs=100)\n",
    "\n",
    "    #loss over time\n",
    "    plt.plot(train.history['loss'],label='loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend('Adam')\n",
    "    pred = model.predict(x_test)\n",
    "    return r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing behins here: ----------------\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1565\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0943\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0624\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0426\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0302\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0132\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0121\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0100\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0096\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0096\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0096\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0096\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0096\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Printing behins here: ----------------\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1185\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0933\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0789\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0673\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0579\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0503\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0441\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0349\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0286\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0262\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0199\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0165\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0145\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0129\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0127\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0125\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0123\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 950us/step - loss: 0.0115\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0113\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0112\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0111\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0110\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0105\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0100\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0099\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 950us/step - loss: 0.0097\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0096\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0096\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 938us/step - loss: 0.0096\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0095\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "9/9 [==============================] - 0s 748us/step\n",
      "Printing behins here: ----------------\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.5003\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0888\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0533\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0465\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0409\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0363\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0325\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0294\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0268\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0247\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0229\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 971us/step - loss: 0.0200\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 999us/step - loss: 0.0153\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 974us/step - loss: 0.0144\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0131\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0129\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0126\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0124\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0120\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0117\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0115\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0113\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0111\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 968us/step - loss: 0.0110\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0102\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0100\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 940us/step - loss: 0.0099\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1000us/step - loss: 0.0097\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "9/9 [==============================] - 0s 997us/step\n",
      "Printing behins here: ----------------\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1952\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1186\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0849\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0629\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0487\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0390\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0325\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0282\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0131\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0128\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0125\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0123\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0119\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0113\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0110\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0099\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 975us/step - loss: 0.0097\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0096\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 980us/step - loss: 0.0093\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 995us/step - loss: 0.0092\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0092\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "9/9 [==============================] - 0s 623us/step\n",
      "Printing behins here: ----------------\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.2307\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.1525\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0992\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0654\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0445\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0317\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0114\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0109\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0105\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0096\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 998us/step - loss: 0.0094\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0094\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0094\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.0093\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 996us/step - loss: 0.0093\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0093\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 938us/step - loss: 0.0093\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.0093\n",
      "9/9 [==============================] - 0s 873us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SGD_score  = []\n",
    "mini_batch_sgd_score= []\n",
    "momentum_score = []\n",
    "nesterov_score = []\n",
    "rms_prop_score = []\n",
    "ADAM_score = []\n",
    "for train_index, test_index in kf.split(scaled_x):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = scaled_y[train_index], scaled_y[test_index]\n",
    "    # SGD_score.append(SGD_model(x_train,y_train,x_test,y_test))\n",
    "    # mini_batch_sgd_score.append(MINI_BATCH_SGD_model(x_train,y_train,x_test,y_test))\n",
    "    momentum_score.append(MOMENTUM_model(x_train,y_train,x_test,y_test))\n",
    "    # nesterov_score.append(NESTEROV_model(x_train,y_train,x_test,y_test))\n",
    "    # rms_prop_score.append(RMSPROP_model(x_train,y_train,x_test,y_test))\n",
    "    # ADAM_score.append(ADAM_model(x_train,y_train,x_test,y_test))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7810509903748457,\n",
       " 0.7378344073707732,\n",
       " 0.7679840126164018,\n",
       " 0.6306667111985713,\n",
       " 0.7459003067726547]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(SGD_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6859073461332793"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ADAM_score) \n",
    "# for 0.001 = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7340598802725693"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ADAM_score)\n",
    "# for 0.01 = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7379998144367365"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ADAM_score)\n",
    "# for learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395091601511976"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mini_batch_sgd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7287750837320033"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(momentum_score) \n",
    "# without decay rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377358670796849"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(momentum_score)\n",
    "# with decay rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397622437255729"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(nesterov_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7280993363428557"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rms_prop_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7375670063487549"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(momentum_score) # for age bmi smoker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid_activation(x):\n",
    "\t# compute the sigmoid activation value for a given input\n",
    "\treturn 1.0 / (1 + np.exp(-x))\n",
    "def sigmoid_deriv(x):\n",
    "\t# compute the derivative of the sigmoid function ASSUMING\n",
    "\t# that the input \"x\" has already been passed through the sigmoid\n",
    "\t# activation function\n",
    "\treturn x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):\n",
    "\t# take the dot product between our features and weight matrix\n",
    "\tpreds = sigmoid_activation(X.dot(W))\n",
    "\t# apply a step function to threshold the outputs to binary\n",
    "\t# class labels\n",
    "\tpreds[preds <= 0.5] = 0\n",
    "\tpreds[preds > 0] = 1\n",
    "\t# return the predictions\n",
    "\treturn preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X, y, batchSize):\n",
    "\t# loop over our dataset \"X\" in mini-batches, yielding a tuple of\n",
    "\t# the current batched data and labels\n",
    "\tfor i in np.arange(0, X.shape[0], batchSize):\n",
    "\t\tyield (X[i:i + batchSize], y[i:i + batchSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X, np.ones((X.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 1.],\n",
       "       [0., 0., 1., ..., 3., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training...\n"
     ]
    }
   ],
   "source": [
    "# initialize our weight matrix and list of losses\n",
    "print(\"[INFO] training...\")\n",
    "W = np.random.randn(X.shape[1], 1)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "        \"batch-size\": 32,\n",
    "        \"epochs\": 100,\n",
    "        \"alpha\": 0.01,\n",
    "})\n",
    "print(args[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "(32, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (32,10) (32,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# preds = preds.flatten()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# now that we have our predictions, we need to determine the\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# \"error\", which is the difference between our predictions\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# and the true values\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(preds\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 17\u001b[0m error \u001b[39m=\u001b[39m (preds \u001b[39m-\u001b[39;49m batchY)\n\u001b[0;32m     18\u001b[0m epochLoss\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msum(error \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[0;32m     19\u001b[0m \u001b[39m# the gradient descent update is the dot product between our\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# (1) current batch and (2) the error of the sigmoid\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# derivative of our predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\generic.py:2016\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   2013\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2014\u001b[0m     \u001b[39mself\u001b[39m, ufunc: np\u001b[39m.\u001b[39mufunc, method: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39minputs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m   2015\u001b[0m ):\n\u001b[1;32m-> 2016\u001b[0m     \u001b[39mreturn\u001b[39;00m arraylike\u001b[39m.\u001b[39;49marray_ufunc(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\arraylike.py:273\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m kwargs \u001b[39m=\u001b[39m _standardize_out_kwarg(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[39m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m result \u001b[39m=\u001b[39m maybe_dispatch_ufunc_to_dunder_op(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\arraylike.py:198\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__rsub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mrsub)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   6111\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 6112\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1350\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    168\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    170\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "File \u001b[1;32mc:\\Users\\ayush\\Desktop\\Study\\Surender sir research paper internship\\env\\Lib\\site-packages\\pandas\\core\\roperator.py:15\u001b[0m, in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrsub\u001b[39m(left, right):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m-\u001b[39;49m left\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (32,10) (32,) "
     ]
    }
   ],
   "source": [
    "# loop over the desired number of epochs\n",
    "for epoch in np.arange(0, args[\"epochs\"]):\n",
    "\t# initialize the total loss for the epoch\n",
    "\tepochLoss = []\n",
    "\t# loop over our data in batches\n",
    "\tfor (batchX, batchY) in next_batch(x_train, y_train, args[\"batch-size\"]):\n",
    "\t\t# take the dot product between our current batch of features\n",
    "\t\t# and the weight matrix, then pass this value through our\n",
    "\t\t# activation function\n",
    "\t\tpreds = sigmoid_activation(batchX.dot(W))\n",
    "\t\tprint(preds)\n",
    "\t\t# preds = preds.flatten()\n",
    "\t\t# now that we have our predictions, we need to determine the\n",
    "\t\t# \"error\", which is the difference between our predictions\n",
    "\t\t# and the true values\n",
    "\t\tprint(preds.shape)\n",
    "\t\terror = (preds - batchY)\n",
    "\t\tepochLoss.append(np.sum(error ** 2))\n",
    "\t\t# the gradient descent update is the dot product between our\n",
    "\t\t# (1) current batch and (2) the error of the sigmoid\n",
    "\t\t# derivative of our predictions\n",
    "\t\td = error * sigmoid_deriv(preds)\n",
    "\t\tgradient = batchX.T.dot(d)\n",
    "\t\t# gradient = gradient.flatten()\n",
    "\t\t# in the update stage, all we need to do is \"nudge\" the\n",
    "\t\t# weight matrix in the negative direction of the gradient\n",
    "\t\t# (hence the term \"gradient descent\" by taking a small step\n",
    "\t\t# towards a set of \"more optimal\" parameters\n",
    "\t\tprint(args[\"alpha\"])\n",
    "\t\tW = W+ -args[\"alpha\"] * gradient\n",
    "\t\t# update our loss history by taking the average loss across all\n",
    "\t# batches\n",
    "\tloss = np.average(epochLoss)\n",
    "\tlosses.append(loss)\n",
    "\t# check to see if an update should be displayed\n",
    "\tif epoch == 0 or (epoch + 1) % 5 == 0:\n",
    "\t\tprint(\"[INFO] epoch={}, loss={:.7f}\".format(int(epoch + 1),\n",
    "\t\t\tloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "086edbbad6d007afd932f3998127bea1c36f47a35b43b79d0f508f10f9e57cc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
